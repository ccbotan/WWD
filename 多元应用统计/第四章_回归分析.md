[TOC]

# 回归分析

## 4.1 经典多元线性回归

> 假定因变量与x_1, x_2, \cdots, x_m 线性相关。收集到的n组数据(y_t, x_{t1}, x_{t2}, \cdots, x_{tm}) (t = 1, 2, \cdots, n) 满足一下回归模型 
>
> Suppose C = (1_n | X) , 
>
> Y = C\beta + \epsilon , 
>
> E(\epsilon) = 0_n,  D(\epsilon)  = \sigma^2 I_n 



或  

> Y = C\beta + \epsilon , 
>
> \epsilon ~ N_n(0, \sigma^2 I_n) 

经典多元线性回归模型 , 并称上述模型为 **经典多元线性回归模型**, 其中 Y 是可观测的随机向量， \epsilon  是不可观测的随机向量，  C  是已知矩阵, \beta, \sigma^2 是未知参数， 并设 n  > m , 且 rank(C) = m + 1



### 参数向量  $\beta$ 的最小二乘估计 

#### 定义 4.1.1  在模型（4.1.2）中,  参数$\beta$ 的最小二乘估计量 b = ($b_0, b_1, \cdots, b_m$)' 使得误差平方和 Q(b) 最小，即 

> Q(b) = min_{一切\beta} Q(\beta) ,  其中 Q(\beta) = \sum^n_{t = 1}\epsilon_t^2  = (Y - C \beta)'(Y - C\beta)

#### 定理 4.1.1 设rank(C) = m + 1 $\le $ n , 则 $\beta = b = (C'C)^{-1}C'Y$ 是$\beta$ 的最小二乘估计 





参数向量 \beta 的最小二乘估计 $\dot{\beta} = b $正好是 m + 1 阶的线性方程组 

C'C$\beta$ = C' Y 的解。 常称以上方程组为  **正规方程**

> 设 $\dot{Y}  =  C\dot{\beta} = C(C'C)^{-1}C'Y = HY $ 为  Y的预测向量值， 其中 $H_{n * n} C (C'C)^{-1} C'$ 称为 
>
> **帽子矩阵**

 此时残差向量 $\dot{ \epsilon} = Y - \dot{Y}  = (I_n - H) Y ,  且残差平方和为 Q(\dot{\beta}) = \dot{\epsilon}'\dot{\epsilon} = Y'Y - Y'C\dot{\beta}$ 

   

#### 3.最小二乘估计的统计性质

##### 性质1: b 是 \beta  的最小方差线性无偏估计量 

##### 性质2: b ~ $N_{m + 1}(\beta, \sigma^2 (C'C)^{-1})$

##### 性质3: 在$\epsilon $~ $N_0(0, \sigma^2 I_n) $ 的假定下， b 还是一切无偏估计中方差最小的估计 

#### 4.$\sigma^2$ 的估计 

> $\dot{\sigma^2} = \frac{1}{n} \sum^n_{i = 1}[y_i - (b_0 + b_1x_{i1k} + \cdots + b_m x_{im})]^2$ = $\frac{1}{n}(Y - Cb)'(Y - Cb) = \frac{1}{n} Q(b)$

> 但因 $\dot{\sigma^2}$ 不是 $\sigma$ 的无偏估计量, 通常取  $s^2 = \frac{1}{n - m - 1}Q(b)$ 作为  \sigma^2的估计量,  它是\sigma^2 的无偏估计量 





我们假定 E(Y) = $\beta_0 + \beta_1 x_1 + \cdots + \beta_m x_m$ 如果  Y 与自变量 $x_1, x_2, \cdots, x_m$ 之间均无线性相关关系， 则  (4.1.2) 模型中 x_i (i = 1, 2, \cdots, m ) 的系数 \beta_i 应均为  0， 故检验 Y 与 x_1, x_2, \cdots, x_m 是否线性相关的问题就等于检验假设  

H_0: \beta_1 = \beta_2 = \cdots = \beta_m = 0 

1.  平方和分解公式 

> 恒有公式: $\sum^n_{i = 1} (y_i - \overline{y})^2 = \sum^n_{i = 1}(y_i - \dot{y_i})^2 + \sum^n_{i  = 1}(\dot{y_i} - \overline{y})^2$
>
> 其中 $\overline{y} = \frac{1}{n}\sum^n_{i = 1}y_i$

而 

$\dot{\beta} = (C'C)^{-1}C'Y$ 是\beta 的最小二乘估计。 公式(4.1.4)称为**平方和分解公式**

> 平方和分解公式等号的左边 $\sum^n_{i = 1}(y_i - \overline{y})^2体现了Y  的观测值y_1, y_2, \cdots, y_n$总波动大小， 称为 **总偏差平方和**, 记为 $l_{yy}$(或 TSS) . (4.1.4) 式 等号右边的第二项 $\sum^n_{i = 1}(\dot{y_i} - \overline{y})^2$ 体现了n个估计值$\dot{y_1}, \dot{y_2}, \cdots, \dot{y_n}$  的波动大小， 称为 **回归平方和**, 记为 U(或 MSS); 等号右边第一项$\sum^n_{i = 1}(y_i - \dot{})$









